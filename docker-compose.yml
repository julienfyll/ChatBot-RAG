services:
  rag-backend:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: rag_container
    ports:
      - "8001:8000"  # Port hôte 8001 -> Port conteneur 8000
    volumes:
      - ./config.json:/app/config.json
      - ./data/raw:/app/data/raw
      - ./chroma_db_local:/app/chroma_db_local
      - ./data/processed_texts:/app/data/processed_texts
      - ./scripts:/app/scripts
      - ./prompts:/app/prompts
      
    extra_hosts:
      - "host.docker.internal:host-gateway" # Permet au conteneur de voir ton LLM local (Linux)
    environment:
      - PYTHONUNBUFFERED=1
      # Ces variables aident parfois PyTorch à trouver le driver
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTORCH_ALLOC_CONF=expandable_segments:True

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]